name: Scrape RateX Data (Continuous Loop)

on:
  # Allow manual trigger
  workflow_dispatch:
  
  # Run on push to test
  push:
    branches: [ web_scraping_start, main ]

jobs:
  scrape-loop:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max (GitHub Actions limit)
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: server/package.json
      
      - name: Install dependencies ONCE
        working-directory: ./server
        run: npm install
      
      - name: Run continuous scraper loop
        working-directory: ./server
        run: node scrape-and-update.js
        env:
          GIST_ID: d3a1db6fc79e168cf5dff8d3a2c11706
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
          PORT: 3000
      
      # Note: This job will run for 6 hours, then automatically restart
      # GitHub Actions has a 6-hour timeout, after which the workflow will
      # be cancelled and can be manually restarted or triggered by a new commit
