name: Scrape RateX Data

on:
  # Run every 5 minutes automatically (only works on default branch)
  schedule:
    - cron: '*/5 * * * *'  # Every 5 minutes
  
  # Allow manual trigger from GitHub UI or API
  workflow_dispatch:
  
  # Trigger on push for testing
  push:
    branches: [ web_scraping_start, main ]

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # Increased for Phase 2 parallel scraping (RateX + Exponent)
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: server/package.json
      
      - name: Install dependencies
        working-directory: ./server
        run: npm install
      
      - name: Run scraper (single execution)
        working-directory: ./server
        run: node scrape-once.js
        env:
          GIST_ID: d3a1db6fc79e168cf5dff8d3a2c11706
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}
          SENDGRID_API_KEY: ${{ secrets.SENDGRID_API_KEY }}
          MAILGUN_API_KEY: ${{ secrets.MAILGUN_API_KEY }}
          MAILGUN_DOMAIN: ${{ secrets.MAILGUN_DOMAIN }}
          RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
          ALERT_FROM_EMAIL: ${{ secrets.ALERT_FROM_EMAIL }}
      
      - name: Upload debug screenshots (if any)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-screenshots
          path: /tmp/exponent-*.png
          if-no-files-found: ignore
          retention-days: 7
      
      - name: Show completion
        run: echo "âœ… Scraped and updated Gist at $(date)"
